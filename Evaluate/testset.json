{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Answer","type":"string"},{"name":"Question","type":"string"},{"name":"Tool","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":24,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[50] RowanZellers,XimingLu,JackHessel,YoungjaeYu,JaeSungPark,JizeCao,AliFarhadi,andYejinChoi. Merlot:Multimodalneural\nscriptknowledgemodels.AdvancesinNeuralInformationProcessingSystems,34:23634–23651,2021.\n[51] LisaAnneHendricks,JohnMellor,RosaliaSchneider,Jean-BaptisteAlayrac,andAidaNematzadeh.Decouplingtheroleofdata,attention,\nandlossesinmultimodaltransformers.TransactionsoftheAssociationforComputationalLinguistics,9:570–585,2021.\nXiao et al.: PreprintsubmittedtoElsevier Page 25 of 32","type":"Document"},"Question":"What role do attention mechanisms play in improving the performance of multimodal neural script knowledge models?","Tool":"similarity_search"},{"index":1,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","file_path":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","page":0,"total_pages":23,"Author":"","CreationDate":"D:20241001011553Z","Creator":"LaTeX with hyperref","Keywords":"","ModDate":"D:20241001011553Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX-1.40.25","Subject":"","Title":"","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"short due to inherent data noise. To tackle this, we refined medical image-text\npairsfromPubMedandemployedMLLMs(GPT-4V)inan’unblinded’capacity\ntodenoiseandreformatthedata,resultinginthecreationofthePubMedVision\ndatasetwith1.3millionmedicalVQAsamples. Ourvalidationdemonstratesthat:\n(1)PubMedVisioncansignificantlyenhancethemedicalmultimodalcapabilities\nof current MLLMs, showing significant improvement in benchmarks including\ntheMMMUHealth&Medicinetrack;(2)manualchecksbymedicalexpertsand\nempiricalresultsvalidatethesuperiordataqualityofourdatasetcomparedtoother\ndataconstructionmethods. UsingPubMedVision,wetraina34BmedicalMLLM\nHuatuoGPT-Vision,whichshowssuperiorperformanceinmedicalmultimodal\nscenariosamongopen-sourceMLLMs.\n1 Introduction\nMultimodal Large Language Models (MLLMs), such as GPT4-V, show limited performance in\nmedicalapplications,particularlyinlackingvisualknowledgespecifictothemedicaldomain[1,2].","type":"Document"},"Question":"What role do medical image-text pairs play in enhancing the capabilities of Multimodal Large Language Models in a specific domain?","Tool":"similarity_search"},{"index":2,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":0,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"crucialfortheirresponsibleandeffectiveintegrationintomedical a more comprehensive approach to medical data analysis and\npractice. decision-making.\nIndexTerms—MultimodalLargeLanguageModels(MLLMs),\nA key strength of MLLMs is their ability to bridge the\nMedicalImaging,ClinicalDecisionSupport,PatientEngagement,\nData Integration gap between unstructured and structured data, a particularly\nvaluable feature in healthcare where information is often\nI. INTRODUCTION fragmentedacrossdifferentformats.Forexample,theREALM\nThe landscape of healthcare is constantly evolving, driven framework leverages LLMs to encode clinical notes and in-\nby an unprecedented explosion of data. Electronic health tegrates them with time-series EHR data, enhancing clinical\nrecords, medical imaging, genomic sequencing, and wearable predictions by incorporating external knowledge from knowl-\nsensors generate an overwhelming amount of information, edge graphs [4]. In a similar vein, the MedDr model [5]","type":"Document"},"Question":"What role do Large Language Models play in bridging gaps between different types of healthcare data to support more comprehensive decision-making and patient engagement?","Tool":"similarity_search"},{"index":3,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":29,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[177] ReeceAlexanderJamesClough,WilliamAnthonySparkes,OliverThomasClough,JoshuaThomasSykes,AlexanderThomasSteventon,\nandKateKing.Transforminghealthcaredocumentation:harnessingthepotentialofaitogeneratedischargesummaries.BJGPOpen,2024.\n[178] HarshaNori,NicholasKing,ScottMayerMcKinney,DeanCarignan,andEricHorvitz.Capabilitiesofgpt-4onmedicalchallengeproblems.\narXivpreprintarXiv:2303.13375,2023.\n[179] ZhengyuanYang,LinjieLi,KevinLin,JianfengWang,Chung-ChingLin,ZichengLiu,andLijuanWang. Thedawnoflmms:Preliminary\nexplorationswithgpt-4v(ision).arXivpreprintarXiv:2309.17421,9(1):1,2023.\n[180] ZhichaoYang,ZonghaiYao,MahbubaTasmin,ParthVashisht,WonSeokJang,FeiyunOuyang,BeiningWang,DanBerlowitz,andHong\nYu. Performanceofmultimodalgpt-4vonusmlewithimage:Potentialforimagingdiagnosticsupportwithexplanations. medRxiv,pages\n2023–10,2023.\n[181] SalKhan.Harnessinggpt-4sothatallstudentsbenefit.anonprofitapproachforequalaccess.KhanAcademyBlog,2023.","type":"Document"},"Question":"What is the main goal of harnessing the potential of artificially generated summaries to support healthcare documentation?","Tool":"similarity_search"},{"index":4,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":27,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[123] AndrewJaegle,FelixGimeno,AndyBrock,OriolVinyals,AndrewZisserman,andJoaoCarreira.Perceiver:Generalperceptionwithiterative\nattention.InProceedingsofthe38thInternationalConferenceonMachineLearning,volume139,pages4651–4664.PMLR,18–24Jul2021.\n[124] ShezhengSong,XiaopengLi,andShashaLi. Howtobridgethegapbetweenmodalities:Acomprehensivesurveyonmultimodallarge\nlanguagemodel.arXivpreprintarXiv:2311.07594,2023.\n[125] JunnanLi,DongxuLi,SilvioSavarese,andStevenHoi.BLIP-2:Bootstrappinglanguage-imagepre-trainingwithfrozenimageencodersand\nlargelanguagemodels.InProceedingsofthe40thInternationalConferenceonMachineLearning,volume202ofProceedingsofMachine\nLearningResearch,pages19730–19742.PMLR,23–29Jul2023.\n[126] LinliYao,LeiLi,ShuhuaiRen,LeanWang,YuanxinLiu,XuSun,andLuHou. Deco:Decouplingtokencompressionfromsemantic\nabstractioninmultimodallargelanguagemodels.arXivpreprintarXiv:2405.20985,2024.","type":"Document"},"Question":"What is the primary goal of bridging the gap between modalities that is discussed in the document?","Tool":"similarity_search"},{"index":5,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":27,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[127] HaotianLiu,ChunyuanLi,YuhengLi,andYongJaeLee.Improvedbaselineswithvisualinstructiontuning.In2024IEEE\/CVFConference\nonComputerVisionandPatternRecognition(CVPR),pages26286–26296,2024.\n[128] AlistairEWJohnson,TomJPollard,LuShen,Li-weiHLehman,MenglingFeng,MohammadGhassemi,BenjaminMoody,PeterSzolovits,\nLeoAnthonyCeli,andRogerGMark.Mimic-iii,afreelyaccessiblecriticalcaredatabase.ScientificData,3(1):1–9,2016.\n[129] AlistairEWJohnson,LucasBulgarelli,LuShen,AlvinGayles,AyadShammout,StevenHorng,TomJPollard,SichengHao,Benjamin\nMoody,BrianGow,etal.Mimic-iv,afreelyaccessibleelectronichealthrecorddataset.ScientificData,10(1):1,2023.\nXiao et al.: PreprintsubmittedtoElsevier Page 28 of 32","type":"Document"},"Question":"What kind of data or information do biomedical research studies often rely on for their critical care and electronic health record datasets?","Tool":"similarity_search"},{"index":6,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":26,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"Qingyao Xu, Ke Li, Peng Zhai, and Lihua Zhang. PediatricsGPT: Large language models as chinese medical assistants for pediatric\napplications.InTheThirty-eighthAnnualConferenceonNeuralInformationProcessingSystems,2024.\n[83] HonglinXiong,ShengWang,YitaoZhu,ZihaoZhao,YuxiaoLiu,LinlinHuang,QianWang,andDinggangShen.Doctorglm:Fine-tuning\nyourchinesedoctorisnotaherculeantask.arXivpreprintarXiv:2304.01097,2023.\n[84] YirongChen,ZhenyuWang,XiaofenXing,ZhipeiXu,KaiFang,JunhongWang,SihangLi,JielingWu,QiLiu,XiangminXu,etal.\nBianque:Balancingthequestioningandsuggestionabilityofhealthllmswithmulti-turnhealthconversationspolishedbychatgpt. arXiv\npreprintarXiv:2310.15896,2023.\n[85] PengchengHe,XiaodongLiu,JianfengGao,andWeizhuChen.Deberta:Decoding-enhancedbertwithdisentangledattention.arXivpreprint\narXiv:2006.03654,2020.\n[86] ZhenzhongLan,MingdaChen,SebastianGoodman,KevinGimpel,PiyushSharma,andRaduSoricut.Albert:Alitebertforself-supervised","type":"Document"},"Question":"What role do large language models play in assisting Chinese medical professionals, particularly in pediatric applications?","Tool":"similarity_search"},{"index":7,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","file_path":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","page":5,"total_pages":23,"Author":"","CreationDate":"D:20241001011553Z","Creator":"LaTeX with hyperref","Keywords":"","ModDate":"D:20241001011553Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX-1.40.25","Subject":"","Title":"","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"additionofmedicalmultimodaldatatoLLaVA-v1.5-LLaMA3-8Bsignificantlyenhancesperformance,\nrevealingsubstantialpotentialforimprovingmedicalimageunderstanding. Notably,theuseofthe\nPubMedVisionledtoan11.7%increaseinoverallaccuracy,significantlyoutperformingtheearlier\nLLaVA_Meddataset. Additionally,asdetailedinAppendixA,fine-tuningonthetrainingsetsof\nthese four datasets indicates that PubMedVision can also significantly improves performance in\ndownstreammedicalmultimodaltasks.\n6","type":"Document"},"Question":"What is the primary goal of injecting medical visual knowledge into multimodal large language models at scale?","Tool":"similarity_search"},{"index":8,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","file_path":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","page":2,"total_pages":23,"Author":"","CreationDate":"D:20241001011553Z","Creator":"LaTeX with hyperref","Keywords":"","ModDate":"D:20241001011553Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX-1.40.25","Subject":"","Title":"","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"Case Analysis Figure 1 presents examples generated by these methods. It can be ob-\nserved that Native-Caption captions are ambiguous and contain content unrelated to the image.\nLLM-Reformatted misinterpretsthreesub-imagesasaCTslide,leadingtomisleadingdescriptions,\nandfailstoexcludeirrelevantcontent. GPT4v-Distill generatesfactuallyincorrectdescriptionsdue\ntothelackofcontextualtext. Incontrast, MLLM-Reformatted producessuperiordescriptionsby\nleveragingbothvisualinformationandcontextualcues. Itaccuratelyandthoroughlydescribesthe\nkeyinformationoftheimage. ThesubsequentexperimentinSection4.3furtherdemonstratesthe\nhigherdataqualityofMLLM-Reformatted.\n3","type":"Document"},"Question":"What is the primary advantage of using MLLM-Reformatted compared to other methods for generating image descriptions?","Tool":"similarity_search"},{"index":9,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":11,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"stages. For medical LLMs, scientific literatures and web data are primarily used during pre-training and continual\npre-trainingphasestoincorporatemedicalknowledgeandfacilitatedomainadaptation.Incontrast,QA,dialogue,and\ninstruction-followingdataaretypicallyemployedduringthefine-tuningphasetoenhanceinteractioncapabilitiesand\ninstruction-followingperformance.FormedicalMLLMs,image-captionpairsarewidelyusedduringpre-trainingto\nalignvisualfeatureswithtextrepresentations,whileinstruction-followingdataiscommonlyappliedforfine-tuning.\nFurthermore,theextensivecontentofEHRsandscientificliteratureoftenmakesthemfoundationalsourcesforother\ndatatypes.Forexample,PMC-15M[151]isderivedfrom3millionPMCarticles,yielding15millionimage-caption\npairs.Finally,studieshavedemonstratedthatfine-tuningmodelswithsubstantialhigh-qualitysyntheticdatagenerated\nbyChatGPTcansignificantlyenhancedownstreamtaskperformance[154].Asaresult,AI-assisteddatageneration","type":"Document"},"Question":"What is the primary use of scientific literatures and web data for medical LLMs during certain stages of pre-training and continual training?","Tool":"similarity_search"},{"index":10,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":6,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"Additionally, ensuring data privacy and obtaining informed accessibility and applicability in diverse linguistic contexts.\nconsent are critical ethical considerations that require careful The potential of bilingual fine-tuned LLMs, such as Taiyi,\nattention, particularly when dealing with sensitive medical can achieve superior performance on biomedical NLP tasks\ninformation [35]. compared to general LLMs [98]. However, more research is\nneeded to develop effective methodsfor creating and evaluat-\nB. InterdisciplinaryCollaborationandKnowledgeIntegration\ning multilingual medical LLMs that can cater to the needs of\n1) FosteringEffectiveInterdisciplinaryCollaboration: The diverse patient populations [84], [99].\ndevelopment of clinically relevant and useful MultiModal\nLarge Language Models (MLLMs) requires bridging the gap\nD. Ethical and Regulatory Framework\nbetweencomputerscienceandmedicine.Thisinterdisciplinary\nchallengecallsforcollaborationamongmedicalprofessionals,","type":"Document"},"Question":"What factors are critical ethical considerations when dealing with sensitive medical information in the context of large language models?","Tool":"similarity_search"},{"index":11,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":9,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[54] R. Bhayana, “Chatbots and Large Language Models in Radiology: A\nresearchandhealthcare,” MedComm–FutureMedicine, vol.2,no.2,\nPractical Primer for Clinical and Research Applications,” Radiology,\nmay172023.\nvol.310,no.1,jan12024.\n[34] H.-Y. Zhou, S. Adithan, J. N. Acosta, E. J. Topol, and P. Rajpurkar,\n“AGeneralistLearnerforMultifaceted MedicalImageInterpretation,” [55] N. Yildirim, H. Richardson, M. T. Wetscherek, J. Bajwa, J. Jacob,\narXivpreprintarXiv:2405.07988, 2024. M.A.Pinnock,S.Harris,D.CoelhoDeCastro,S.Bannur,S.Hyland,\n[35] J. C. L. Ong, S. Y.-H. Chang, W. William, A. J. Butte, N. H. Shah, P. Ghosh, M. Ranjit, K. Bouzid, A. Schwaighofer, F. Pe´rez-Garc´ıa,\nL.S.T.Chew,N.Liu,F.Doshi-Velez,W.Lu,J.Savulescu,andD.S.W. H. Sharma, O. Oktay, M. Lungren, J. Alvarez-Valle, A. Nori, and\nTing, “Ethical and regulatory challenges of large language models in A. Thieme, “Multimodal Healthcare AI: Identifying and Designing","type":"Document"},"Question":"What are the ethical and regulatory challenges associated with the use of large language models in medical practice?","Tool":"similarity_search"},{"index":12,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","file_path":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","page":4,"total_pages":23,"Author":"","CreationDate":"D:20241001011553Z","Creator":"LaTeX with hyperref","Keywords":"","ModDate":"D:20241001011553Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX-1.40.25","Subject":"","Title":"","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"3.2 DataReformattingwithMLLMs\nPrompt Template Different QA scenarios\n{medical_images}\nPlease complete the following tasks based on the medical images and reference Standard Q&A Doctor to Doctor\ninformation provided by me.\n1. Generate a detailed and professional description (Image_description). The\ndescription must reflect your professionalism and provide as many details as Senior Doctor and Intern Evaluator and AI Model\npossible from the image. The more comprehensive and precise, the better.\n2. {QA_scenario_prompt}\nDoctor and Patient's Family Doctor and Difficult Patient\nThe contextual text is marked by <reference>. You need to refer to it to ensure\nthe accuracy of the content you generate, but do not mention the existence of\nthis reference information when generating data. Intern and Specialist Doctor AI Model Assisting Doctor\nYour reply must be in JSON format, formatted as","type":"Document"},"Question":"Here is a question that can only be answered from this document:\n\nWhat is the primary goal of generating detailed and professional descriptions of medical images based on reference Standard Q&A Doctor-to-Doctor information provided by a doctor?","Tool":"similarity_search"},{"index":13,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":7,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"strates that while LLMs can effectively analyze data from ships between different modalities, leading to more accurate\nspecificmedicalspecialties,theirperformanceoftendecreases and robust predictions [112].\nwhen applied to other areas [73]. Additional efforts should\nC. Interpretability and Explainability\nfocusondevelopingmethodstoenhancethegeneralizationca-\npabilities of MLLMs, ensuring that they perform consistently A critical area for future research is enhancing the in-\nand reliably across different medical contexts, diverse patient terpretability and explainability of MLLMs. This lack of\npopulations, and various languages. transparency in current LLMs MLLMs can hinder trust and\nDeveloping Efficient and Scalable Models adoption in clinical settings. Traditional evaluation methods\nThe large size and computational demands of MLLMs forMLLMsareusuallyinsufficientforclinicalsettings,asthey","type":"Document"},"Question":"What are the limitations of large language models when applied to areas outside their training data?","Tool":"similarity_search"},{"index":14,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","file_path":"..\/Papers\/HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale.pdf","page":12,"total_pages":23,"Author":"","CreationDate":"D:20241001011553Z","Creator":"LaTeX with hyperref","Keywords":"","ModDate":"D:20241001011553Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX-1.40.25","Subject":"","Title":"","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"A MoreExperiments\nFine-tunedResultsofVQABenchmarks ToverifywhetherPubMedVisioncanenhancedown-\nstreamtasks,wefine-tunedthemodelusingthetrainingsetoftheBenchmarks. AsshowninFigure\n7,PubMedVisioneffectivelyimprovesdownstreammedicaltasks,significantlybenefitingallfour\nVQAdownstreamtasks.\nVQA-RAD SLAKE PathVQA PMC-VQA\nModel Avg.\n(Finetuned) (Finetuned) (Finetuned) (Finetuned)\nFine-tuningonthetrainingset.\nLLaVA-v1.5-LLaMA3-8B 63.3 68.9 85.2 50.3 66.9\n+LLaVA_Med 66.3 69.5 90.7 52.7 69.8\n+ PubMedVision 68.9 84.1 93.0 57.3 75.8\nTable7: ResultsonVQABenchmarksafterfine-tuningonthetasktrainingsets. Alldatasetswere\ntrainedusingtheirrespectivein-builttrainingsets,over2trainingepochs.\nResultsonvalidationsetofMMMU Table8presentsthevalidationresultsofMMMU,where\nLLaVA-v1.6-34Bexhibitssuperioroverallperformance. However,comparedtothetestsetresultsof\nMMMU(officialsubmission)inTable4,LLaVA-v1.5-LLaMA3-8BcombinedwithPubMedVision","type":"Document"},"Question":"What is the effect of fine-tuning a medical language model using PubMed Vision on its performance for downstream tasks?","Tool":"similarity_search"},{"index":15,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":13,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine\nCollecting Human Feedback Training The Reward Model Policy Optimization\nWhat are the symptoms of stomach ulcers? How to prevent HIV\/AIDS?\nWhat are the symptoms of stomach ulcers?\nLarge Language Model D ＞ C ＞ B ＞ A\nLarge Language Model\nA B What are the What are the\nSevere stomach... sL to on mg a-t ce hrm ... sts oy mm ap ct ho um lcs e o rf s? sts oy mm ap ct ho um lcs e o rf s?\nUsing safe sexual practices...\nD A\nC D\nIndigestion and ... Sto rm ea fec rh t ou .l .c .ers Sto rm ea fec rh t ou .l .c .ers Severe stomach...\nHuman Feedback\nD ＞ C ＞ B ＞ A\nRM\nRM\nRD RA R\nWhat are the symptoms of stomach ulcers?\nD ＞ C ＞ B ＞ A\nLoss = log(σ(RD - RA))\nFig. 6. Pipeline of Reinforcement Learning from Human Feedback. Left illustrates the Collect Human Feedback phase: A\nlabeler provides a single prompt to the model, ranks multiple responses, and collect the prompt along with the labeled","type":"Document"},"Question":"What are some common health issues that can be addressed by using large language models and multimodal large language models in medicine?","Tool":"similarity_search"},{"index":16,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":14,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"fluencyofgeneratedtext,theyfallshortinassessingclinicaldialoguequality[152]andalignmentwithhumanvalues,\nnecessitatingtheinclusionofhumanevaluation.\n4.3.2. HumanEvaluation\nHuman evaluation is an essential approach to assess medical LLMs and MLLMs, as it addresses aspects that\nautomaticevaluationmetricsmayfailtocapture.Forexample,Tuetal.[152]highlightedthatmetricssuchasBLEU\nandROUGEfailtoreflecttheclinicalqualityofmedicalconsultations.Toaddressthis,23medicalexpertsfromthe\nUnitedStates,theUnitedKingdom,andIndiawereinvitedtoevaluatemodel-generatedresponsesbasedonaccuracy,\nappropriateness, and comprehensiveness. Similarly, Yang et al. [69] engaged human experts to assess the safety,\naccuracy,andethicalimplicationsofmodel-generatedresponses.\nClearly,humanevaluationcanencompasscriticalaspectssuchassafetyandhelpfulness,whichareessentialfor\nmedicalLLMsandMLLMs.DespiteitsabilitytoevaluatediversecapabilitiesofmedicalLLMsandMLLMs,human","type":"Document"},"Question":"What role do human evaluators play in assessing medical Large Language Models (LLMs) and Multimodal LLMs?","Tool":"similarity_search"},{"index":17,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","file_path":"..\/Papers\/A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine.pdf","page":5,"total_pages":32,"Author":"Hanguang XiaoⰠ﻿Feizhong ZhouⰠ﻿Xingyue LiuⰠ整⁡氮","CreationDate":"D:20241231022219Z","Creator":"LaTeX3; cas-sc.cls; hyperref.sty","Keywords":"","ModDate":"D:20241231022219Z","PTEX.Fullbanner":"This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5","Producer":"pdfTeX;","Subject":"Complex STM Content","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Trapped":"False"},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"Apollo[80] Qwen 7 ApolloCorpora CPT,SFT AEM 2024\/03\nBioMedLM[81] Transformer 2.7 PubMedCenter,Pile PT,SFT AEM 2024\/03\nPediatricsGPT[82] Baichuan2 7\/13 PedCorpus CPT,SFT,DPO AEM,Human,AI 2024\/05\nDoctorGLM[83] ChatGLM 6 ChatDoctor,HealthcareMagic,MedDialog,CMD. IFT Human 2023\/04\nEncoder-Decoder BianQue[84] ChatGLM 6 BianQueCorpus IFT AEM 2023\/10\nSoulChat[22] ChatGLM 6 SoulChatCorpus IFT AEM,Human 2023\/11\n1Encoder-onlymodelsarenotincludedastheytypicallybelongtothePLM,notLLM.\n2\"CPT\"meanscontinuouspre-training,\"IFT\"meansinstructionfine-tuning,\"SFT\"meanssupervisedfine-tuning,\"RLHF\"meansreinforcementlearningfromhumanfeedback,\"RLAIF\"meansreinforcement\nlearningfromAIfeedback,\"DPO\"meansdirectpreferenceoptimization.\n3\"AEM\"meansautomaticevaluationmetrics.\nutilizethemaskedlanguagemodeling(MLM)taskduringpre-training,whererandomtokensinsentencesaremasked,\nand the model is trained to predict these tokens accurately. This pre-training approach equips encoder-only LMs","type":"Document"},"Question":"What is the primary goal of pre-training large language models using the masked language modeling (MLM) task?","Tool":"similarity_search"},{"index":18,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":9,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"NaturalLanguage ProcessingWorkshop,2024. C. Naugler, “Assessing the research landscape and clinical utility of\n[46] G.Team,R.Anil,S.Borgeaud,Y.Wu,J.-B.Alayrac,J.Yu,R.Soricut, large language models: a scoping review,” BMC Medical Informatics\nJ.Schalkwyk,A.M.Dai,A.Hauthetal.,“Gemini:afamilyofhighly andDecisionMaking, vol.24,no.1,mar122024.\ncapable multimodal models,”arXivpreprintarXiv:2312.11805, 2023. [66] S.Schmidgall, R. Ziaei, C.Harris, E.Reis, J.Jopling, and M.Moor,\n[47] Iryna Hartsock and Ghulam Rasool, “Vision-Language Models for “Agentclinic: a multimodal agent benchmark to evaluate AI in simu-\nMedical Report Generation and Visual Question Answering: A Re- lated clinical environments,” 2024.\nview,”arXiv.org,2024. [67] Daniel McDuff, M.Schaekermann, TaoTu,AnilPalepu, AmyWang,\n[48] YutaoHu,Tian-XinLi,QuanfengLu,WenqiShao,JunjunHe,YuQiao, JakeGarrison, KaranSinghal, YashSharma,Shekoofeh Azizi, Kavita","type":"Document"},"Question":"What role do large language models play in medical practice and clinical decision-making?","Tool":"similarity_search"},{"index":19,"Answer":{"id":null,"lc_attributes":{},"lc_secrets":{},"metadata":{"source":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","file_path":"..\/Papers\/From Text to Multimodality_ Exploring the Evolution and Impact of Large Language Models in Medical Practice.pdf","page":10,"total_pages":12,"Producer":"GPL Ghostscript 10.01.2","CreationDate":"D:20241210202328-05'00'","ModDate":"D:20241210202328-05'00'","Creator":"LaTeX with hyperref","Title":"","Subject":"","Author":"","Keywords":""},"model_computed_fields":{},"model_config":{"extra":"ignore"},"model_extra":null,"model_fields":{"id":{"alias":null,"alias_priority":null,"default":null,"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"metadata":{"alias":null,"alias_priority":null,"default":{},"default_factory_takes_validated_data":false,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"page_content":{"alias":null,"alias_priority":null,"default":{},"default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null},"type":{"alias":null,"alias_priority":null,"default":"Document","default_factory":null,"default_factory_takes_validated_data":null,"deprecated":null,"deprecation_message":null,"description":null,"discriminator":null,"evaluated":true,"examples":null,"exclude":null,"field_title_generator":null,"frozen":null,"init":null,"init_var":null,"json_schema_extra":null,"kw_only":null,"metadata":[],"metadata_lookup":{"strict":{"strict":true},"gt":{},"ge":{},"lt":{},"le":{},"multiple_of":{},"min_length":{},"max_length":{},"pattern":null,"allow_inf_nan":null,"max_digits":null,"decimal_places":null,"union_mode":null,"coerce_numbers_to_str":null,"fail_fast":{"fail_fast":true}},"repr":true,"serialization_alias":null,"title":null,"validate_default":null,"validation_alias":null}},"model_fields_set":["page_content","metadata"],"page_content":"[68] JundaWang,Zhichao Yang,Zonghai Yao,andHongYu,“Jmlr:Joint [89] J.Clusmann,F.R.Kolbinger,H.S.Muti,Z.I.Carrero,J.-N.Eckardt,\nMedical LLM and Retrieval Training for Enhancing Reasoning and N. G. Laleh, C. M. L. Lo¨ffler, S.-C. Schwarzkopf, M. Unger, G. P.\nProfessional QuestionAnsweringCapability,” arXiv.org,2024. Veldhuizen, S.J.Wagner, andJ.N.Kather, “Thefuture landscape of\n[69] KilianCarolan,LauraFennelly,andA.Smeaton,“AReviewofMulti- largelanguagemodelsinmedicine,”CommunicationsMedicine,vol.3,\nModalLargeLanguageandVisionModels,”arXiv.org,2024. no.1,oct102023.\n[70] AminDada, Marie Bauer, AmandaButler Contreras, OsmanAlperen [90] A. M. Bean, K. Korgul, F. Krones, R. McCraith, and A. Mahdi,\nKoras,C.Seibold,KalebE.Smith,andJensKleesiek,“Clue:AClinical “Exploringthelandscapeoflargelanguagemodelsinmedicalquestion\nLanguage Understanding Evaluation forLLMs,”arXiv.org,2024. answering,” 2023.","type":"Document"},"Question":"What is the primary goal of training medical large language models for enhancing reasoning and professional question-answering capability?","Tool":"similarity_search"},{"index":20,"Answer":"AIMS: To explore the potential of multimodal large language models in alleviating the documentation burden on nurses while enhancing the quality and efficiency of patient care.\nDESIGN: This position paper is informed by expert discussions and a literature review.\nMETHODS: We extensively reviewed nursing documentation practices and advanced technologies, such as multimodal large language models. We analysed key challenges, solutions and impacts to propose a futuristic multimodal large language model-driven model for nursing documentation.\nRESULTS: Multimodal large language models offer transformative capabilities by integrating multimodal audio, video and text data during patient encounters to dynamically update patient records in real time. This reduces manual data entry, enabling nurses to focus more on direct patient care. These systems also enhance care personalisation through predictive analytics and interoperability, which support seamless workflows and better patient outcomes. While predictive analytics could improve patient care by identifying trends and risk factors from nursing documentation, further research is required to validate its accuracy and clinical utility in real-world settings. Ethical, legal and practical challenges, including privacy concerns and biases in artificial intelligence models, require careful consideration for successful implementation.\nCONCLUSION: Transitioning to multimodal large language model-driven documentation systems can significantly reduce administrative burdens, improve nurse satisfaction and enhance patient care. However, successful integration demands interdisciplinary collaboration, robust ethical frameworks and technological advancements.\nIMPLICATIONS FOR THE PROFESSION AND PATIENT CARE: Implementing multimodal large language models could alleviate professional burnout, improve nurse-patient interactions, and provide dynamic, up-to-date patient records that facilitate informed decision making. These advancements align with the goals of patient-centred care by enabling more meaningful engagement between nurses and patients.\nIMPACT: The problem being addressed is the administrative burden of nursing documentation. We suggest that multimodal large language models minimise manual documentation, enhance patient care quality and significantly impact nurses and patients in diverse healthcare settings globally.","Question":"What's the abstract of the paper An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality.?","Tool":"cypher_search"},{"index":21,"Answer":"2410.01812v5","Question":"What's the DOI of the paper From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice?","Tool":"cypher_search"},{"index":22,"Answer":16,"Question":"How many keywords were used?","Tool":"cypher_search"},{"index":23,"Answer":["ArXiv","PubMed"],"Question":"Which are the databases available?","Tool":"cypher_search"},{"index":24,"Answer":"2024","Question":"Which year was the paper titled From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice published in?","Tool":"cypher_search"},{"index":25,"Answer":"PubMed","Question":"Which database indexed the paper An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality.?","Tool":"cypher_search"},{"index":26,"Answer":["Liu M","Niu Q","Chen K","Li M","Feng P","Bi Z","Yan LK","Zhang Y","Yin CH","Fei C","Liu J","Peng B","Wang T","Wang Y","Chen S"],"Question":"Who are the authors of the research paper From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice?","Tool":"cypher_search"},{"index":27,"Answer":["care","multimodal","large","documentation","patient"],"Question":"What keywords are associated with the paper An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality.?","Tool":"cypher_search"},{"index":28,"Answer":"AUTHORED_BY","Question":"What is the relationship between the author Chen K and the paper From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice?","Tool":"cypher_search"},{"index":29,"Answer":"PUBLISHED_IN","Question":"How is the paper A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine linked to the year 2024?","Tool":"cypher_search"},{"index":30,"Answer":"KEYWORDS","Question":"What connection exists between the keyword mllms and the paper A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine?","Tool":"cypher_search"},{"index":31,"Answer":"PUBLISHER","Question":"In what way is the database ArXiv related to the paper HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale?","Tool":"cypher_search"},{"index":32,"Answer":false,"Question":"Was the paper An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality. authored by Li M","Tool":"cypher_search"},{"index":33,"Answer":true,"Question":"Is the keyword llm mllms used to describe the paper A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine?","Tool":"cypher_search"},{"index":34,"Answer":false,"Question":"Was the paper HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale published in the year 2025?","Tool":"cypher_search"},{"index":35,"Answer":false,"Question":"Is the paper HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale indexed in the database PubMed?","Tool":"cypher_search"},{"index":36,"Answer":"True: ['From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice']","Question":"Did the author Chen S write any paper that contains the keyword healthcare?","Tool":"cypher_search"},{"index":37,"Answer":"True: ['An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality.']","Question":"Was the keyword mllms associated with any paper published in the year 2025?","Tool":"cypher_search"},{"index":38,"Answer":"False: []","Question":"Has the author Michalowski M published any paper indexed in the database ArXiv?","Tool":"cypher_search"},{"index":39,"Answer":"False: []","Question":"Has the keyword language model been used in any paper published in the database PubMed?","Tool":"cypher_search"}]}