{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"DOI","type":"string"},{"name":"Title","type":"string"},{"name":"Abstract","type":"string"},{"name":"Year","type":"string"},{"name":"Authors","type":"string"},{"name":"PDF_URL","type":"string"},{"name":"Database","type":"string"},{"name":"Keywords","type":"string"},{"name":"References","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"DOI":"2405.08603v3","Title":"A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine","Abstract":"Since the release of ChatGPT and GPT-4, large language models (LLMs) and\nmultimodal large language models (MLLMs) have attracted widespread attention\nfor their exceptional capabilities in understanding, reasoning, and generation,\nintroducing transformative paradigms for integrating artificial intelligence\ninto medicine. This survey provides a comprehensive overview of the\ndevelopment, principles, application scenarios, challenges, and future\ndirections of LLMs and MLLMs in medicine. Specifically, it begins by examining\nthe paradigm shift, tracing the transition from traditional models to LLMs and\nMLLMs, and highlighting the unique advantages of these LLMs and MLLMs in\nmedical applications. Next, the survey reviews existing medical LLMs and MLLMs,\nproviding detailed guidance on their construction and evaluation in a clear and\nsystematic manner. Subsequently, to underscore the substantial value of LLMs\nand MLLMs in healthcare, the survey explores five promising applications in the\nfield. Finally, the survey addresses the challenges confronting medical LLMs\nand MLLMs and proposes practical strategies and future directions for their\nintegration into medicine. In summary, this survey offers a comprehensive\nanalysis of the technical methodologies and practical clinical applications of\nmedical LLMs and MLLMs, with the goal of bridging the gap between these\nadvanced technologies and clinical practice, thereby fostering the evolution of\nthe next generation of intelligent healthcare systems.","Year":2024,"Authors":["Xiao H","Zhou F","Liu X","Liu T","Li Z","Liu X","Huang X"],"PDF_URL":"http:\/\/arxiv.org\/pdf\/2405.08603v3","Database":"ArXiv","Keywords":"llm, llm mllms, mllms, model, survey","References":[]},{"index":3,"DOI":"2410.01812v5","Title":"From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice","Abstract":"Large Language Models (LLMs) have rapidly evolved from text-based systems to\nmultimodal platforms, significantly impacting various sectors including\nhealthcare. This comprehensive review explores the progression of LLMs to\nMultimodal Large Language Models (MLLMs) and their growing influence in medical\npractice. We examine the current landscape of MLLMs in healthcare, analyzing\ntheir applications across clinical decision support, medical imaging, patient\nengagement, and research. The review highlights the unique capabilities of\nMLLMs in integrating diverse data types, such as text, images, and audio, to\nprovide more comprehensive insights into patient health. We also address the\nchallenges facing MLLM implementation, including data limitations, technical\nhurdles, and ethical considerations. By identifying key research gaps, this\npaper aims to guide future investigations in areas such as dataset development,\nmodality alignment methods, and the establishment of ethical guidelines. As\nMLLMs continue to shape the future of healthcare, understanding their potential\nand limitations is crucial for their responsible and effective integration into\nmedical practice.","Year":2024,"Authors":["Niu Q","Chen K","Li M","Feng P","Bi Z","Yan LK","Zhang Y","Yin CH","Fei C","Liu J","Peng B","Wang T","Wang Y","Chen S","Liu M"],"PDF_URL":"http:\/\/arxiv.org\/pdf\/2410.01812v5","Database":"ArXiv","Keywords":"healthcare, language model, large language, medical, mllms","References":[]},{"index":4,"DOI":"2406.19280v4","Title":"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale","Abstract":"The rapid development of multimodal large language models (MLLMs), such as\nGPT-4V, has led to significant advancements. However, these models still face\nchallenges in medical multimodal capabilities due to limitations in the\nquantity and quality of medical vision-text data, stemming from data privacy\nconcerns and high annotation costs. While pioneering approaches utilize\nPubMed's large-scale, de-identified medical image-text pairs to address these\nlimitations, they still fall short due to inherent data noise. To tackle this,\nwe refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in\nan 'unblinded' capacity to denoise and reformat the data, resulting in the\ncreation of the PubMedVision dataset with 1.3 million medical VQA samples. Our\nvalidation demonstrates that: (1) PubMedVision can significantly enhance the\nmedical multimodal capabilities of current MLLMs, showing significant\nimprovement in benchmarks including the MMMU Health & Medicine track; (2)\nmanual checks by medical experts and empirical results validate the superior\ndata quality of our dataset compared to other data construction methods. Using\nPubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows\nsuperior performance in medical multimodal scenarios among open-source MLLMs.","Year":2024,"Authors":["Chen J","Gui C","Ouyang R","Gao A","Chen S","Chen GH","Wang X","Zhang R","Cai Z","Ji K","Yu G","Wan X","Wang B"],"PDF_URL":"http:\/\/arxiv.org\/pdf\/2406.19280v4","Database":"ArXiv","Keywords":"data, medical, mllms, multimodal, pubmedvision","References":[]},{"index":6,"DOI":"10.1111\/jan.16911","Title":"An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New Reality.","Abstract":"AIMS: To explore the potential of multimodal large language models in alleviating the documentation burden on nurses while enhancing the quality and efficiency of patient care.\nDESIGN: This position paper is informed by expert discussions and a literature review.\nMETHODS: We extensively reviewed nursing documentation practices and advanced technologies, such as multimodal large language models. We analysed key challenges, solutions and impacts to propose a futuristic multimodal large language model-driven model for nursing documentation.\nRESULTS: Multimodal large language models offer transformative capabilities by integrating multimodal audio, video and text data during patient encounters to dynamically update patient records in real time. This reduces manual data entry, enabling nurses to focus more on direct patient care. These systems also enhance care personalisation through predictive analytics and interoperability, which support seamless workflows and better patient outcomes. While predictive analytics could improve patient care by identifying trends and risk factors from nursing documentation, further research is required to validate its accuracy and clinical utility in real-world settings. Ethical, legal and practical challenges, including privacy concerns and biases in artificial intelligence models, require careful consideration for successful implementation.\nCONCLUSION: Transitioning to multimodal large language model-driven documentation systems can significantly reduce administrative burdens, improve nurse satisfaction and enhance patient care. However, successful integration demands interdisciplinary collaboration, robust ethical frameworks and technological advancements.\nIMPLICATIONS FOR THE PROFESSION AND PATIENT CARE: Implementing multimodal large language models could alleviate professional burnout, improve nurse-patient interactions, and provide dynamic, up-to-date patient records that facilitate informed decision making. These advancements align with the goals of patient-centred care by enabling more meaningful engagement between nurses and patients.\nIMPACT: The problem being addressed is the administrative burden of nursing documentation. We suggest that multimodal large language models minimise manual documentation, enhance patient care quality and significantly impact nurses and patients in diverse healthcare settings globally.","Year":"2025","Authors":["Michalowski M","Topaz M","Peltonen LM"],"PDF_URL":"40129115","Database":"PubMed","Keywords":"care, documentation, large, multimodal, patient","References":[]}]}